import time
import cv2
import multiprocessing
from multiprocessing import shared_memory
from api.sender import SenderTCP
from api.receiver import ReceiverProcess
from common.camera import Camera
from common.config import config
from common.detection import FaceDetector


class UserState:
    """çŠ¶æ…‹ç®¡ç†"""
    def __init__(self):
        self.is_send = False  # é€ä¿¡æ¸ˆã¿ãƒ•ãƒ©ã‚°
        self.persist_start_time = None  # é¡”æ¤œå‡ºãŒç¶™ç¶šã—ãŸé–‹å§‹æ™‚åˆ»


class CameraProcess(multiprocessing.Process):
    def __init__(self, camera_id, num_cameras, shared_flags):
        """
        ã‚«ãƒ¡ãƒ©ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆæœŸåŒ–
        :param camera_id: ã“ã®ã‚«ãƒ¡ãƒ©ã®ID
        :param num_cameras: å…¨ã‚«ãƒ¡ãƒ©æ•°
        :param shared_flags: å…±æœ‰ãƒ¡ãƒ¢ãƒªã®é€ä¿¡ãƒ•ãƒ©ã‚°
        """
        super().__init__()
        self.camera_id = camera_id
        self.num_cameras = num_cameras
        self.shared_flags = shared_flags  # å…±æœ‰ãƒ¡ãƒ¢ãƒªã¸ã®å‚ç…§
        self.camera = Camera(camera_id)
        self.detector = FaceDetector()
        self.sender = SenderTCP()
        self.user_state = UserState()

    def run(self):
        """ ã‚«ãƒ¡ãƒ©å‡¦ç†ã‚’é–‹å§‹ """
        print(f"ğŸ¥ Camera {self.camera_id} started | Press 'ESC' to exit")

        while True:
            # ä»–ã®ã‚«ãƒ¡ãƒ©ã®ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
            if any(self.shared_flags[i] for i in range(self.num_cameras) if i != self.camera_id):
                # ä»–ã®ã‚«ãƒ¡ãƒ©ãŒã‚²ãƒ¼ãƒ ä¸­ãªã‚‰é»’èƒŒæ™¯ã«ã™ã‚‹
                frame = self.create_black_screen()
            else:
                frame = self.camera.get_frame()
                if frame is None:
                    continue

                face, face_size = self.detect_face(frame)
                self.handle_face_state(face_size)

                # é¡”ãŒã‚ã‚‹å ´åˆã€ãƒ•ãƒ¬ãƒ¼ãƒ ã«æç”»
                if face is not None:
                    x1, y1, x2, y2 = face
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    text = f"Face Size: {face_size}"
                    cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)

            cv2.imshow(f"Camera {self.camera_id}", frame)
            if cv2.waitKey(1) & 0xFF == 27:
                break

        # çµ‚äº†å‡¦ç†
        self.camera.release()
        cv2.destroyAllWindows()

    def detect_face(self, frame):
        """ é¡”ã‚’æ¤œå‡ºã—ã€ã‚µã‚¤ã‚ºã‚’å–å¾— """
        face = self.detector.detect_face(frame)
        if not face:
            return None, None

        x1, y1, x2, y2 = face
        face_size = (x2 - x1) * (y2 - y1)
        return face, face_size

    def handle_face_state(self, face_size):
        """ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡”ãŒæ¤œå‡ºã•ã‚ŒãŸéš›ã®å‡¦ç† """
        current_time = time.time()

        if face_size is not None and face_size > config.MIN_FACE_SIZE:
            if self.user_state.persist_start_time is None:
                self.user_state.persist_start_time = current_time  # åˆå›æ¤œå‡ºæ™‚é–“ã‚’è¨˜éŒ²
            elif (current_time - self.user_state.persist_start_time) >= config.FACE_PERSIST_DURATION:
                if not self.user_state.is_send:
                    print(f"ğŸ‘¤ Camera {self.camera_id}: User detected! Sending request...")
                    self.sender.send_request("attract", "hello", self.camera_id)
                    self.shared_flags[self.camera_id] = 1  # é€ä¿¡ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
                    self.user_state.is_send = True
        else:
            self.user_state.persist_start_time = None

        # `receiver.py` ã‹ã‚‰ `Action.WAIT` ã‚’å—ä¿¡ã—ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
        response = self.sender.send_request("status", "", self.camera_id)
        if response and "type" in response and response["type"] == "wait":
            print(f"ğŸ”„ Camera {self.camera_id}: Resetting user state...")
            self.shared_flags[self.camera_id] = 0  # é€ä¿¡ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            self.user_state.is_send = False
            self.user_state.persist_start_time = None  # çµŒéæ™‚é–“ãƒªã‚»ãƒƒãƒˆ

    def create_black_screen(self):
        """ ä»–ã®ã‚«ãƒ¡ãƒ©ãŒã‚²ãƒ¼ãƒ ä¸­ã®ã¨ãã®é»’èƒŒæ™¯ç”»é¢ã‚’ä½œæˆ """
        frame = 255 * (cv2.cvtColor(cv2.imread(config.BLACK_SCREEN_PATH), cv2.COLOR_BGR2GRAY) > 0).astype("uint8")
        cv2.putText(frame, "Another camera is playing", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        return frame


# è¨­å®š
NUM_CAMERAS = 4  # ã‚«ãƒ¡ãƒ©ã®å°æ•°

# å…±æœ‰ãƒ¡ãƒ¢ãƒªã®ä½œæˆï¼ˆå„ã‚«ãƒ¡ãƒ©ã®é€ä¿¡ãƒ•ãƒ©ã‚°ã‚’å…±æœ‰ï¼‰
shared_mem = shared_memory.SharedMemory(create=True, size=NUM_CAMERAS)
shared_flags = memoryview(shared_mem.buf).cast('B')

# ã‚«ãƒ¡ãƒ©ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½œæˆï¼ˆè¤‡æ•°å°ï¼‰
cameras = [CameraProcess(i, NUM_CAMERAS, shared_flags) for i in range(NUM_CAMERAS)]
receiver = ReceiverProcess(shared_flags)  # `receiver.py` ã‚‚ãƒ•ãƒ©ã‚°ã‚’å‚ç…§

# ã™ã¹ã¦ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹
receiver.start()
for cam in cameras:
    cam.start()

# çµ‚äº†å‡¦ç†
receiver.join()
for cam in cameras:
    cam.join()
